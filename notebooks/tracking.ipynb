{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.9.0 64-bit ('conrl': conda)",
   "display_name": "Python 3.9.0 64-bit ('conrl': conda)",
   "metadata": {
    "interpreter": {
     "hash": "39f6d57b2d002d2858f1280da29f7eb418c3912465fbfaf442673e32f51e9fe0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/nassim/dev/conrl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.conrl import ConRL\n",
    "from src.qlearning import QLearningAgent\n",
    "from src.utils import *\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import gym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as mc\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "np.set_printoptions(precision=3, linewidth=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdodicin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "state_size = (10, 10)\n",
    "window_size = (env.observation_space.high - env.observation_space.low)/state_size\n",
    "num_episodes = 500\n",
    "max_step = 1000\n",
    "env._max_episode_steps = max_step\n",
    "\n",
    "q_params = {\n",
    "    \"gamma\": 0.9,\n",
    "    \"alpha\": 0.1,\n",
    "    \"alpha_decay_rate\": 0,\n",
    "    \"min_alpha\": 0.1,\n",
    "    \"epsilon\": 1.0,\n",
    "    \"epsilon_decay_rate\": 0,\n",
    "    \"min_epsilon\": 0.1\n",
    "}\n",
    "\n",
    "q_params[\"epsilon_decay_rate\"] = (q_params[\"epsilon\"] - q_params[\"min_epsilon\"])/(num_episodes//2)\n",
    "q_params[\"alpha_decay_rate\"] = (q_params[\"alpha\"] - q_params[\"min_alpha\"])/(num_episodes//2)\n",
    "\n",
    "mlgng_params = {\n",
    "    \"ndim\": 2, \n",
    "    \"e_w\":0.5, \n",
    "    \"e_n\":0.1, \n",
    "    \"l\":10, \n",
    "    \"a\":0.5, \n",
    "    \"b\":1-0.05, # Java impl. does it like this\n",
    "    \"k\":1000.0, \n",
    "    \"max_nodes\": 10, \n",
    "    \"max_age\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "act_dict = {\n",
    "    0: \"Push left\",\n",
    "    1: \"No push\",\n",
    "    2: \"Push right\"\n",
    "}\n",
    "\n",
    "act_symbol = {\n",
    "    0:  \"o\",\n",
    "    1: \"^\",\n",
    "    2: \"s\",\n",
    "}\n",
    "\n",
    "act_color = cm.Dark2(np.linspace(0.1, 1, 3, endpoint=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 3461<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb/run-20201110_121448-3nxkh5ij/logs/debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb/run-20201110_121448-3nxkh5ij/logs/debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">fluent-cloud-32</strong>: <a href=\"https://wandb.ai/dodicin/con-rl/runs/3nxkh5ij\" target=\"_blank\">https://wandb.ai/dodicin/con-rl/runs/3nxkh5ij</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.10 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.9<br/>\n                Syncing run <strong style=\"color:#cdcd00\">solar-fire-33</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/dodicin/con-rl\" target=\"_blank\">https://wandb.ai/dodicin/con-rl</a><br/>\n                Run page: <a href=\"https://wandb.ai/dodicin/con-rl/runs/2w89c4wp\" target=\"_blank\">https://wandb.ai/dodicin/con-rl/runs/2w89c4wp</a><br/>\n                Run data is saved locally in <code>wandb/run-20201110_121537-2w89c4wp</code><br/><br/>\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "  entity=\"dodicin\",\n",
    "  project=\"con-rl\",\n",
    "  notes=\"test\",\n",
    "  tags=[\"q-learning\", \"mlgng\"],\n",
    "  config={\"q_params\": q_params,\n",
    "        \"mlgng_params\": mlgng_params})\n",
    "\n",
    "def wandb_log():\n",
    "   wandb.log({\n",
    "        'reward': stats_cr.episode_rewards[episode], \n",
    "        'steps': stats_cr.episode_lengths[episode],\n",
    "        'selector': np.mean(stats_cr.selector_dist[episode]),\n",
    "        'global_error': conrl.mlgng.get_last_stat_tuple(\"global_error\")\n",
    "        })\n",
    "\n",
    "    data = conrl.mlgng.get_nodes()\n",
    "    if data.shape[1]>1:\n",
    "        table = wandb.Table(data=data.T.tolist(), columns = [\"position\", \"velocity\", \"action\"])\n",
    "        wandb.log({\"nodes\" : wandb.plot.scatter(table, \"position\", \"velocity\", \"action\")})\n",
    "\n",
    "    length = state_size[0]*state_size[1]\n",
    "    conrl_state_actions = np.zeros((length, 3))\n",
    "\n",
    "    for idx in range(length):\n",
    "        state = np.unravel_index(idx, state_size)\n",
    "        best_a, _, _, _ = conrl._simple_action_selector(state)\n",
    "        conrl_state_actions[idx] = state + (best_a, )\n",
    "\n",
    "    table = wandb.Table(data=conrl_state_actions.tolist(), columns = [\"position\", \"velocity\", \"action\"])\n",
    "    wandb.log({\"best_actions\" : wandb.plot.scatter(table, \"position\", \"velocity\", \"action\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode 0/500, Reward -1000.0, Total steps 999.0, Epsilon: 1.00, Alpha: 0.10, Time 0.211\n",
      "\t MLGNG nodes per action layer: 0 0 0\n",
      "Episode 100/500, Reward -1000.0, Total steps 999.0, Epsilon: 0.64, Alpha: 0.10, Time 1.051\n",
      "\t MLGNG nodes per action layer: 4 3 3\n",
      "Episode 200/500, Reward -450.0, Total steps 449.0, Epsilon: 0.28, Alpha: 0.10, Time 0.597\n",
      "\t MLGNG nodes per action layer: 10 10 10\n",
      "Episode 300/500, Reward -160.0, Total steps 159.0, Epsilon: 0.10, Alpha: 0.10, Time 0.395\n",
      "\t MLGNG nodes per action layer: 10 10 9\n",
      "Episode 400/500, Reward -391.0, Total steps 390.0, Epsilon: 0.10, Alpha: 0.10, Time 0.823\n",
      "\t MLGNG nodes per action layer: 10 10 10\n"
     ]
    }
   ],
   "source": [
    "stats_cr = EpisodeStats(\n",
    "        episode_lengths=np.zeros(num_episodes),\n",
    "        episode_rewards=np.zeros(num_episodes),\n",
    "        selector_dist=np.zeros((num_episodes, max_step)).astype(int))\n",
    "\n",
    "conrl = ConRL(action_size=env.action_space.n, state_size=state_size, update_threshold=10)\n",
    "conrl.init_support(**q_params)\n",
    "conrl.init_mlgng(**mlgng_params)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    done = False\n",
    "    success = False\n",
    "    step = 0\n",
    "\n",
    "    start = time.time()\n",
    "    obs = env.reset()\n",
    "\n",
    "    state = get_discrete_state(obs, window_size, env)\n",
    "    while not done:\n",
    "        next_state, reward, done, selected = conrl.step(state, env, window_size=window_size, discretize=get_discrete_state)\n",
    "        state = next_state\n",
    "        \n",
    "        # Stats logging\n",
    "        stats_cr.episode_rewards[episode] += reward\n",
    "        stats_cr.episode_lengths[episode] = step\n",
    "        stats_cr.selector_dist[episode][step] = selected\n",
    "\n",
    "        step+=1\n",
    "        if step >= max_step:\n",
    "            break\n",
    "    \n",
    "    conrl.support.decay_epsilon(episode)\n",
    "\n",
    "    # Wandb logging\n",
    "    # wandb_log()\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "        print(\"Episode {}/{}, Reward {}, Total steps {}, Epsilon: {:.2f}, Alpha: {:.2f}, Time {:.3f}\".format(episode, num_episodes, stats_cr.episode_rewards[episode], stats_cr.episode_lengths[episode], conrl.support.epsilon, conrl.support.alpha, time.time()-start))\n",
    "        conrl.mlgng.print_stats(one_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 3492<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>wandb/run-20201110_121537-2w89c4wp/logs/debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>wandb/run-20201110_121537-2w89c4wp/logs/debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>reward</td><td>-233.0</td></tr><tr><td>steps</td><td>232.0</td></tr><tr><td>selector</td><td>0.233</td></tr><tr><td>_step</td><td>1488</td></tr><tr><td>_runtime</td><td>457</td></tr><tr><td>_timestamp</td><td>1605010997</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>reward</td><td>▁▁▁▁▁▁▁▁▁█▁▁▁▁▆▆▇▇▁▆▇▆▄▁▇▆██▇▅▇█▅█▁█▆▇▇█</td></tr><tr><td>steps</td><td>█████████▁████▃▃▂▂█▃▂▃▅█▂▃▁▁▂▄▂▁▄▁█▁▃▂▂▁</td></tr><tr><td>selector</td><td>▁████████▂████▄▄▃▃█▄▃▄▅█▃▃▂▂▃▅▃▂▅▂█▂▄▃▃▂</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 989 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">solar-fire-33</strong>: <a href=\"https://wandb.ai/dodicin/con-rl/runs/2w89c4wp\" target=\"_blank\">https://wandb.ai/dodicin/con-rl/runs/2w89c4wp</a><br/>\n                "
     },
     "metadata": {}
    }
   ],
   "source": [
    " run.finish()"
   ]
  }
 ]
}